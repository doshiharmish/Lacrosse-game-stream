{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea206360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IST769 Midterm\n",
    "#-----------------\n",
    "\n",
    "# You will turn this file in along with screenshots as instructed on Blackboard\n",
    "\n",
    "# YOUR NAME: Harmish Kamlesh Doshi\n",
    "# YOUR EMAIL: hadoshi@syr.edu\n",
    "# YOUR SUID: 208610770"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e4ca1e-f3e8-4470-8f6f-d6a11ede28ad",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be4bcf08-45b2-4d33-b2eb-4f7ae6997cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3254652-59ff-490d-9e2d-00d9d77e2baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/jovyan/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      "com.microsoft.azure#spark-mssql-connector_2.12 added as a dependency\n",
      "com.microsoft.sqlserver#mssql-jdbc added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-ddef2ece-3b3d-4012-862d-8902b7e4b219;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.1.2 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.271 in central\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;3.0.1 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;4.0.5 in central\n",
      "\tfound org.mongodb#bson;4.0.5 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;4.0.5 in central\n",
      "\tfound com.microsoft.azure#spark-mssql-connector_2.12;1.2.0 in central\n",
      "\tfound com.microsoft.sqlserver#mssql-jdbc;12.2.0.jre11 in central\n",
      ":: resolution report :: resolve 619ms :: artifacts dl 18ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.271 from central in [default]\n",
      "\tcom.microsoft.azure#spark-mssql-connector_2.12;1.2.0 from central in [default]\n",
      "\tcom.microsoft.sqlserver#mssql-jdbc;12.2.0.jre11 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.1.2 from central in [default]\n",
      "\torg.mongodb#bson;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;4.0.5 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;3.0.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   8   |   0   |   0   |   0   ||   8   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-ddef2ece-3b3d-4012-862d-8902b7e4b219\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 8 already retrieved (0kB/17ms)\n",
      "24/03/09 04:37:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "minio_user = \"minio\"\n",
    "passwd = \"SU2orange!\"\n",
    "mongo_user = \"mongo\"\n",
    "#user = \"sidearm\"\n",
    "#passwd = \"Sidearm12345\"\n",
    "s3_bucket = \"gamestreams\"\n",
    "s3_server = \"http://minio:9000\"\n",
    "s3_access_key = minio_user\n",
    "s3_secret_key = passwd\n",
    "mongo_uri = f\"mongodb://{mongo_user}:{passwd}@mongo:27017/admin?authSource=admin\"\n",
    "server_name = \"jdbc:sqlserver://mssql\"\n",
    "database_name = \"sidearmdb\"\n",
    "mssql_user = \"sa\"\n",
    "mssql_pw = \"SU2orange!\"\n",
    "mssql_url = server_name + \";\" + \"databaseName=\" + database_name + \";encrypt=true;trustServerCertificate=true;\"\n",
    "\n",
    "jars = [\n",
    "    \"org.apache.hadoop:hadoop-aws:3.1.2\",\n",
    "    \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\",\n",
    "    \"com.microsoft.azure:spark-mssql-connector_2.12:1.2.0\",\n",
    "    \"com.microsoft.sqlserver:mssql-jdbc:12.2.0.jre11\"\n",
    "]\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName('jupyter-pyspark') \\\n",
    "        .config(\"spark.jars.packages\",\",\".join(jars) )\\\n",
    "        .config(\"spark.hadoop.fs.s3a.endpoint\", s3_server ) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\", s3_access_key) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\", s3_secret_key) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.fast.upload\", True) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.path.style.access\", True) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .config(\"spark.mongodb.input.uri\", mongo_uri) \\\n",
    "        .config(\"spark.mongodb.output.uri\", mongo_uri) \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\") # Keeps the noise down!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502e3844-adbc-4400-8c75-194e4ed36da6",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a906046a-3efc-4e1e-8b36-819a6b223476",
   "metadata": {},
   "source": [
    "## Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d93a740-0b7c-410f-a8ed-2ad5734c34c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-----+-----+------+\n",
      "| id|  name|number|shots|goals|teamid|\n",
      "+---+------+------+-----+-----+------+\n",
      "|  1|   sam|     6|   56|   23|   101|\n",
      "|  2| sarah|     1|   85|   34|   101|\n",
      "|  3| steve|     2|   60|   20|   101|\n",
      "|  4| stone|    13|   33|   10|   101|\n",
      "|  5|  sean|    17|   26|    9|   101|\n",
      "|  6|   sly|     8|   78|   15|   101|\n",
      "|  7|   sol|     9|   52|   20|   101|\n",
      "|  8| shree|     4|   20|    4|   101|\n",
      "|  9|shelly|    15|   10|    2|   101|\n",
      "| 10| swede|    10|   90|   50|   101|\n",
      "| 11| jimmy|     1|  100|   50|   205|\n",
      "| 12| julie|     9|   10|    0|   205|\n",
      "| 13| james|     2|   45|   15|   205|\n",
      "| 14|  jane|    15|   82|   46|   205|\n",
      "| 15| jimmy|    16|   42|   30|   205|\n",
      "| 16| julie|     8|   67|   32|   205|\n",
      "| 17| james|    17|   40|   14|   205|\n",
      "| 18|  jane|     3|   91|   40|   205|\n",
      "| 19| jimmy|     5|   78|   22|   205|\n",
      "| 20| julie|    22|   83|   19|   205|\n",
      "+---+------+------+-----+-----+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Reading Players Data from MS SQL\n",
    "# HOW TO READ FROM MSSQL\n",
    "players_df = spark.read.format(\"com.microsoft.sqlserver.jdbc.spark\") \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .option(\"url\", mssql_url) \\\n",
    "    .option(\"dbtable\", \"players\") \\\n",
    "    .option(\"user\", mssql_user) \\\n",
    "    .option(\"password\", mssql_pw) \\\n",
    "    .load()\n",
    "\n",
    "players_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86e19093-7594-4069-af2a-612688de77c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- number: string (nullable = true)\n",
      " |-- shots: integer (nullable = true)\n",
      " |-- goals: integer (nullable = true)\n",
      " |-- teamid: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "players_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeecea7-c4eb-4d22-ab31-c9ba67aaea59",
   "metadata": {},
   "source": [
    "## Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df9ecb7a-6455-4fd3-bf75-647a30a714ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------+----+------+\n",
      "| id|         name|conference|wins|losses|\n",
      "+---+-------------+----------+----+------+\n",
      "|101|     syracuse|       acc|  11|     2|\n",
      "|205|johns hopkins|     big10|   9|     4|\n",
      "+---+-------------+----------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading Teams Tables from MSSQL\n",
    "teams_df = spark.read.format(\"com.microsoft.sqlserver.jdbc.spark\") \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .option(\"url\", mssql_url) \\\n",
    "    .option(\"dbtable\", \"teams\") \\\n",
    "    .option(\"user\", mssql_user) \\\n",
    "    .option(\"password\", mssql_pw) \\\n",
    "    .load()\n",
    "\n",
    "teams_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a71b5089-ef4a-4e8b-9fd6-d91fb2015c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- conference: string (nullable = true)\n",
      " |-- wins: integer (nullable = true)\n",
      " |-- losses: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teams_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bc7b10-35aa-42b5-9a8f-14e6f4660873",
   "metadata": {},
   "source": [
    "## Gamestream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4363af34-ebd8-4b4e-b9e8-fbd9eebb512d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2a7bb9b-78b5-4e56-8644-ab729627c4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-------+--------------------+-----------+\n",
      "|event_id|timestamp|team_id|player_jersey_number|hit_or_miss|\n",
      "+--------+---------+-------+--------------------+-----------+\n",
      "|       0|    59:51|    101|                   2|          0|\n",
      "|       1|    57:06|    101|                   6|          0|\n",
      "|       2|    56:13|    205|                   8|          1|\n",
      "|       3|    55:25|    101|                   4|          0|\n",
      "|       4|    55:03|    101|                   1|          1|\n",
      "+--------+---------+-------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Q3\n",
    "# TODO: Read the gamestream.txt from minio\n",
    "#With the help of StructType we are creating a schema for the data to be read from Minio (Object Storage).\n",
    "myschema = StructType([StructField('event_id',IntegerType()),\n",
    "                       StructField('timestamp',StringType()),\n",
    "                       StructField('team_id',IntegerType()),\n",
    "                       StructField('player_jersey_number',IntegerType()),\n",
    "                       StructField('hit_or_miss',IntegerType())\n",
    "                    ])\n",
    "\n",
    "gamestream_df = spark.read\\\n",
    "      .csv(f\"s3a://{s3_bucket}/gamestream.txt\", schema = myschema, sep = ' ')\n",
    "\n",
    "#Read data using csv function so we could apply the schema.\n",
    "\n",
    "gamestream_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1c65e0a-706d-411d-af50-ca8ff567df82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event_id: integer (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- team_id: integer (nullable = true)\n",
      " |-- player_jersey_number: integer (nullable = true)\n",
      " |-- hit_or_miss: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gamestream_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8559281e-1b46-46b0-bdab-08fd3338fb99",
   "metadata": {},
   "source": [
    "# Transform & Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc7183ac-1100-4350-8df4-b2f51ee8476a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- number: integer (nullable = true)\n",
      " |-- shots: integer (nullable = true)\n",
      " |-- goals: integer (nullable = true)\n",
      " |-- teamid: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Correcting \"Jersey Number\" field data type\n",
    "players_df = players_df.withColumn('number', players_df['number'].cast('int'))\n",
    "players_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7c1ee5-ae3a-40d9-bd68-620cd74ca993",
   "metadata": {},
   "source": [
    "### Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c33fa6c-5a30-4d32-86af-3e6f33e5167d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+-----+---------+\n",
      "|team_id|number|shots|goals|team_goal|\n",
      "+-------+------+-----+-----+---------+\n",
      "|    101|     1|    8|    6|       14|\n",
      "|    101|     2|    7|    2|       14|\n",
      "|    101|     4|    5|    1|       14|\n",
      "|    101|     6|    4|    2|       14|\n",
      "|    101|     8|    4|    0|       14|\n",
      "|    101|     9|    5|    0|       14|\n",
      "|    101|    10|    3|    1|       14|\n",
      "|    101|    13|    7|    1|       14|\n",
      "|    101|    15|    3|    1|       14|\n",
      "|    101|    17|    2|    0|       14|\n",
      "|    205|     1|    3|    3|        9|\n",
      "|    205|     2|    3|    1|        9|\n",
      "|    205|     3|    1|    0|        9|\n",
      "|    205|     5|    2|    1|        9|\n",
      "|    205|     8|    2|    1|        9|\n",
      "|    205|     9|    4|    0|        9|\n",
      "|    205|    15|    2|    2|        9|\n",
      "|    205|    16|    1|    0|        9|\n",
      "|    205|    17|    3|    1|        9|\n",
      "|    205|    22|    1|    0|        9|\n",
      "+-------+------+-----+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q4 - PySpark SQL Query\n",
    "#Creating runtime tables for the dataframes to use PySpark SQL\n",
    "gamestream_df.createOrReplaceTempView('gamestream')\n",
    "players_df.createOrReplaceTempView('players')\n",
    "teams_df.createOrReplaceTempView('teams')\n",
    "#Query\n",
    "\n",
    "#Calculating Player Stats\n",
    "#1. To calculate player stats we are left joining players data with gamestream data so we get all players even the players that are missing in gamestream data and then counting their stats like shots and goals. We are also filling NULL values with 0.\n",
    "\n",
    "\n",
    "sql = \"\"\"\n",
    "        WITH temp_tbl1 (team_id, number, shots, goals) AS (\n",
    "            SELECT\n",
    "                p.teamid,\n",
    "                p.number,\n",
    "                COUNT(g.hit_or_miss),\n",
    "                SUM(g.hit_or_miss)\n",
    "            FROM\n",
    "                players p\n",
    "            LEFT JOIN\n",
    "                gamestream g ON g.team_id = p.teamid AND g.player_jersey_number = p.number\n",
    "            GROUP BY\n",
    "                p.teamid, p.number\n",
    "        ),\n",
    "        temp_tbl2 (team_id, team_goal) AS (\n",
    "            SELECT\n",
    "                g.team_id,\n",
    "                SUM(g.hit_or_miss)\n",
    "            FROM\n",
    "                gamestream g\n",
    "            GROUP BY\n",
    "                g.team_id\n",
    "        )\n",
    "        SELECT\n",
    "            t1.team_id,\n",
    "            t1.number,\n",
    "            CASE WHEN t1.shots IS NOT NULL THEN t1.shots ELSE 0 END AS shots ,\n",
    "            CASE WHEN t1.goals IS NOT NULL THEN t1.goals ELSE 0 END AS goals ,\n",
    "            CASE WHEN t2.team_goal IS NOT NULL THEN t2.team_goal ELSE 0 END AS team_goal            \n",
    "        FROM\n",
    "            temp_tbl1 t1\n",
    "        LEFT JOIN\n",
    "            temp_tbl2 t2 ON t2.team_id = t1.team_id\n",
    "        ORDER BY\n",
    "            t1.team_id, t1.number\n",
    "\"\"\"\n",
    "q4_sql_df = spark.sql(sql)\n",
    "q4_sql_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02a55a50-e3c8-437e-bc35-bf71786b18e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:====================================================> (194 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-----+-----+----------+\n",
      "|teamid|number|shots|goals|team_goals|\n",
      "+------+------+-----+-----+----------+\n",
      "|   101|     1|    8|    6|        14|\n",
      "|   101|     2|    7|    2|        14|\n",
      "|   101|     4|    5|    1|        14|\n",
      "|   101|     6|    4|    2|        14|\n",
      "|   101|     8|    4|    0|        14|\n",
      "|   101|     9|    5|    0|        14|\n",
      "|   101|    10|    3|    1|        14|\n",
      "|   101|    13|    7|    1|        14|\n",
      "|   101|    15|    3|    1|        14|\n",
      "|   101|    17|    2|    0|        14|\n",
      "|   205|     1|    3|    3|         9|\n",
      "|   205|     2|    3|    1|         9|\n",
      "|   205|     3|    1|    0|         9|\n",
      "|   205|     5|    2|    1|         9|\n",
      "|   205|     8|    2|    1|         9|\n",
      "|   205|     9|    4|    0|         9|\n",
      "|   205|    15|    2|    2|         9|\n",
      "|   205|    16|    1|    0|         9|\n",
      "|   205|    17|    3|    1|         9|\n",
      "|   205|    22|    1|    0|         9|\n",
      "+------+------+-----+-----+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Q4 - PySpark API\n",
    "#Calculating Player Stats\n",
    "#To calculate player stats we are left joining players data with gamestream data so we get all players even the players that are missing in gamestream data and then counting their stats like shots and goals. We are also filling NULL values with 0. \n",
    "temp_df = players_df\\\n",
    "            .join(gamestream_df, (players_df.teamid == gamestream_df.team_id) & (players_df.number == gamestream_df.player_jersey_number), \"left\")\\\n",
    "            .select(players_df.teamid,players_df.number,gamestream_df.hit_or_miss)\\\n",
    "            .groupby('teamid','number')\\\n",
    "            .agg(count(\"hit_or_miss\").alias(\"shots\")\\\n",
    "                 ,sum(\"hit_or_miss\").alias(\"goals\"))\\\n",
    "            .na.fill(0)\n",
    "\n",
    "#Calculating team Stats\n",
    "#Here are are aggregating goals and grouping by team.\n",
    "temp_df1 = gamestream_df\\\n",
    "            .select('team_id','hit_or_miss')\\\n",
    "            .groupby('team_id')\\\n",
    "            .agg(sum('hit_or_miss').alias('team_goals'))\n",
    "\n",
    "\n",
    "#Merging both dataframes created above to create expected result.\n",
    "\n",
    "q4_api_df = temp_df\\\n",
    "        .join(temp_df1, temp_df1.team_id == temp_df.teamid, \"inner\")\\\n",
    "        .select(\"teamid\",\"number\",\"shots\",\"goals\",\"team_goals\")\\\n",
    "        .sort('teamid','number')\n",
    "q4_api_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a387c93-c0f7-46a9-bbb5-b776f776d1d6",
   "metadata": {},
   "source": [
    "### Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78a6e7fa-2eaf-4795-90c1-d3a0a2db5c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:=================================================>    (185 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+------+------+-----+-----+---------+\n",
      "|event_id|timestamp|teamid|number|shots|goals|team_goal|\n",
      "+--------+---------+------+------+-----+-----+---------+\n",
      "|      70|    00:00|   101|     1|    8|    6|       14|\n",
      "|      70|    00:00|   101|     2|    7|    2|       14|\n",
      "|      70|    00:00|   101|     4|    5|    1|       14|\n",
      "|      70|    00:00|   101|     6|    4|    2|       14|\n",
      "|      70|    00:00|   101|     8|    4|    0|       14|\n",
      "|      70|    00:00|   101|     9|    5|    0|       14|\n",
      "|      70|    00:00|   101|    10|    3|    1|       14|\n",
      "|      70|    00:00|   101|    13|    7|    1|       14|\n",
      "|      70|    00:00|   101|    15|    3|    1|       14|\n",
      "|      70|    00:00|   101|    17|    2|    0|       14|\n",
      "|      70|    00:00|   205|     1|    3|    3|        9|\n",
      "|      70|    00:00|   205|     2|    3|    1|        9|\n",
      "|      70|    00:00|   205|     3|    1|    0|        9|\n",
      "|      70|    00:00|   205|     5|    2|    1|        9|\n",
      "|      70|    00:00|   205|     8|    2|    1|        9|\n",
      "|      70|    00:00|   205|     9|    4|    0|        9|\n",
      "|      70|    00:00|   205|    15|    2|    2|        9|\n",
      "|      70|    00:00|   205|    16|    1|    0|        9|\n",
      "|      70|    00:00|   205|    17|    3|    1|        9|\n",
      "|      70|    00:00|   205|    22|    1|    0|        9|\n",
      "+--------+---------+------+------+-----+-----+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Q5 PySpark SQL\n",
    "#I am using the same query from Q4, extracting eventid and timestamp from the gamestream with the maximum event id, and applying a cross join on the players' data. After preparing the table, I export the data to a DataFrame and then combine both DataFrames based on teamid and jersey number.\n",
    "\n",
    "sql = \"\"\"\n",
    "WITH temp_tbl1 (team_id,number,shots,goals) as (\n",
    "SELECT p.teamid,p.number, count(g.hit_or_miss),sum(g.hit_or_miss)\n",
    "FROM players p\n",
    "LEFT JOIN gamestream g ON g.team_id = p.teamid AND g.player_jersey_number = p.number\n",
    "GROUP BY p.teamid,p.number\n",
    "ORDER BY p.teamid,p.number),\n",
    "temp_tbl2(team_id,team_goal) as (\n",
    "SELECT g.team_id,SUM(g.hit_or_miss)\n",
    "FROM gamestream g\n",
    "GROUP BY g.team_id)\n",
    "select t1.*, t2.team_goal\n",
    "from temp_tbl1 t1\n",
    "left join temp_tbl2 t2 on t2.team_id = t1.team_id\n",
    "order by t1.team_id,t1.number\n",
    "\"\"\"\n",
    "q5_1_df = spark.sql(sql)\n",
    "\n",
    "sql1 = \"\"\"\n",
    "    SELECT g.event_id,\n",
    "            g.timestamp,\n",
    "            p.teamid,\n",
    "            p.number     \n",
    "    FROM\n",
    "            players p\n",
    "    CROSS JOIN\n",
    "            gamestream g\n",
    "    WHERE event_id = (SELECT MAX(event_id) FROM gamestream)\n",
    "\"\"\"\n",
    "\n",
    "q5_2_df = spark.sql(sql1)\n",
    "\n",
    "q5_1_df.\\\n",
    "join(q5_2_df, (q5_1_df.team_id == q5_2_df.teamid) & (q5_1_df.number == q5_2_df.number),\"left\").\\\n",
    "select(q5_2_df.event_id,q5_2_df.timestamp,q5_2_df.teamid,q5_2_df.number,q5_1_df.shots,q5_1_df.goals,q5_1_df.team_goal).\\\n",
    "na.fill(0).\\\n",
    "sort(q5_2_df.teamid,q5_2_df.number).\\\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ff9569c-30e7-4f99-8b5f-52db12c4fa3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:==============================================>       (173 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+------+------+-----+-----+----------+\n",
      "|event_id|timestamp|teamid|number|shots|goals|team_goals|\n",
      "+--------+---------+------+------+-----+-----+----------+\n",
      "|      70|    00:00|   101|     1|    8|    6|        14|\n",
      "|      70|    00:00|   101|     2|    7|    2|        14|\n",
      "|      70|    00:00|   101|     4|    5|    1|        14|\n",
      "|      70|    00:00|   101|     6|    4|    2|        14|\n",
      "|      70|    00:00|   101|     8|    4|    0|        14|\n",
      "|      70|    00:00|   101|     9|    5|    0|        14|\n",
      "|      70|    00:00|   101|    10|    3|    1|        14|\n",
      "|      70|    00:00|   101|    13|    7|    1|        14|\n",
      "|      70|    00:00|   101|    15|    3|    1|        14|\n",
      "|      70|    00:00|   101|    17|    2|    0|        14|\n",
      "|      70|    00:00|   205|     1|    3|    3|         9|\n",
      "|      70|    00:00|   205|     2|    3|    1|         9|\n",
      "|      70|    00:00|   205|     3|    1|    0|         9|\n",
      "|      70|    00:00|   205|     5|    2|    1|         9|\n",
      "|      70|    00:00|   205|     8|    2|    1|         9|\n",
      "|      70|    00:00|   205|     9|    4|    0|         9|\n",
      "|      70|    00:00|   205|    15|    2|    2|         9|\n",
      "|      70|    00:00|   205|    16|    1|    0|         9|\n",
      "|      70|    00:00|   205|    17|    3|    1|         9|\n",
      "|      70|    00:00|   205|    22|    1|    0|         9|\n",
      "+--------+---------+------+------+-----+-----+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Q5 PySpark API\n",
    "#Getting the maximum event id and storing it in a variable.\n",
    "max_event_id = gamestream_df\\\n",
    "                .agg(max('event_id').alias('max_event_id'))\\\n",
    "                .collect()[0]['max_event_id']\n",
    "#Getting eventid, timestamp from gamestream and joining it with dataframe from the Q4\n",
    "q5_api_df = gamestream_df \\\n",
    "               .select('event_id','timestamp') \\\n",
    "               .filter(F.col('event_id') == F.lit(max_event_id)) \\\n",
    "               .join(q4_api_df)\\\n",
    "               .sort('teamid','number')\n",
    "q5_api_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccd6f11-c973-411e-9dde-94a181c4e713",
   "metadata": {},
   "source": [
    "### Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45772864-de11-45c0-999a-dc280e8adfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 61:=========================================>            (153 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+------+-------------+----------+-----------------+-------------------+--------------------+-----------+------------------+------------------+-------------------------+----------+---------+-----------+\n",
      "|event_id|timestamp|teamid|    team_name|conference|team_overall_wins|team_overall_losses|player_jersey_number|player_name|current_game_shots|current_game_goals|current_game_goal_percent|team_goals|team_type|team_result|\n",
      "+--------+---------+------+-------------+----------+-----------------+-------------------+--------------------+-----------+------------------+------------------+-------------------------+----------+---------+-----------+\n",
      "|      70|    00:00|   101|     syracuse|       acc|               11|                  2|                   1|      sarah|                 8|                 6|                     75.0|        14|     home|    Winning|\n",
      "|      70|    00:00|   101|     syracuse|       acc|               11|                  2|                   2|      steve|                 7|                 2|                    28.57|        14|     home|    Winning|\n",
      "|      70|    00:00|   101|     syracuse|       acc|               11|                  2|                   4|      shree|                 5|                 1|                     20.0|        14|     home|    Winning|\n",
      "|      70|    00:00|   101|     syracuse|       acc|               11|                  2|                   6|        sam|                 4|                 2|                     50.0|        14|     home|    Winning|\n",
      "|      70|    00:00|   101|     syracuse|       acc|               11|                  2|                   8|        sly|                 4|                 0|                      0.0|        14|     home|    Winning|\n",
      "|      70|    00:00|   101|     syracuse|       acc|               11|                  2|                   9|        sol|                 5|                 0|                      0.0|        14|     home|    Winning|\n",
      "|      70|    00:00|   101|     syracuse|       acc|               11|                  2|                  10|      swede|                 3|                 1|                    33.33|        14|     home|    Winning|\n",
      "|      70|    00:00|   101|     syracuse|       acc|               11|                  2|                  13|      stone|                 7|                 1|                    14.29|        14|     home|    Winning|\n",
      "|      70|    00:00|   101|     syracuse|       acc|               11|                  2|                  15|     shelly|                 3|                 1|                    33.33|        14|     home|    Winning|\n",
      "|      70|    00:00|   101|     syracuse|       acc|               11|                  2|                  17|       sean|                 2|                 0|                      0.0|        14|     home|    Winning|\n",
      "|      70|    00:00|   205|johns hopkins|     big10|                9|                  4|                   1|      jimmy|                 3|                 3|                    100.0|         9|     away|     Losing|\n",
      "|      70|    00:00|   205|johns hopkins|     big10|                9|                  4|                   2|      james|                 3|                 1|                    33.33|         9|     away|     Losing|\n",
      "|      70|    00:00|   205|johns hopkins|     big10|                9|                  4|                   3|       jane|                 1|                 0|                      0.0|         9|     away|     Losing|\n",
      "|      70|    00:00|   205|johns hopkins|     big10|                9|                  4|                   5|      jimmy|                 2|                 1|                     50.0|         9|     away|     Losing|\n",
      "|      70|    00:00|   205|johns hopkins|     big10|                9|                  4|                   8|      julie|                 2|                 1|                     50.0|         9|     away|     Losing|\n",
      "|      70|    00:00|   205|johns hopkins|     big10|                9|                  4|                   9|      julie|                 4|                 0|                      0.0|         9|     away|     Losing|\n",
      "|      70|    00:00|   205|johns hopkins|     big10|                9|                  4|                  15|       jane|                 2|                 2|                    100.0|         9|     away|     Losing|\n",
      "|      70|    00:00|   205|johns hopkins|     big10|                9|                  4|                  16|      jimmy|                 1|                 0|                      0.0|         9|     away|     Losing|\n",
      "|      70|    00:00|   205|johns hopkins|     big10|                9|                  4|                  17|      james|                 3|                 1|                    33.33|         9|     away|     Losing|\n",
      "|      70|    00:00|   205|johns hopkins|     big10|                9|                  4|                  22|      julie|                 1|                 0|                      0.0|         9|     away|     Losing|\n",
      "+--------+---------+------+-------------+----------+-----------------+-------------------+--------------------+-----------+------------------+------------------+-------------------------+----------+---------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Q6 With the help of Q5 PySpark API\n",
    "#Getting data from the table created in Q5 and joining it with players and teams data to get relevent data.\n",
    "q6_api_df = q5_api_df\\\n",
    "        .join(players_df, (q5_api_df.teamid == players_df.teamid) & (q5_api_df.number == players_df.number))\\\n",
    "        .join(teams_df, q5_api_df.teamid == teams_df.id)\\\n",
    "        .select(q5_api_df.event_id\n",
    "               ,q5_api_df.timestamp\n",
    "               ,q5_api_df.teamid\n",
    "               ,teams_df.name.alias('team_name')\n",
    "               ,teams_df.conference\n",
    "               ,teams_df.wins.alias('team_overall_wins')\n",
    "               ,teams_df.losses.alias('team_overall_losses')\n",
    "               ,q5_api_df.number.alias('player_jersey_number')\n",
    "               ,players_df.name.alias('player_name')\n",
    "               ,q5_api_df.shots.alias('current_game_shots')\n",
    "               ,q5_api_df.goals.alias('current_game_goals')\n",
    "               ,round((q5_api_df.goals / q5_api_df.shots) * 100,2).alias('current_game_goal_percent')\n",
    "               ,q5_api_df.team_goals)\\\n",
    "        .withColumn(\"team_type\", when(q5_api_df.teamid == 101, 'home').otherwise('away'))\\\n",
    "        .na.fill(0)\\\n",
    "        .sort(q5_api_df.teamid,q5_api_df.number)\\\n",
    "#Calculating goals scored by home and away team.\n",
    "home_goals = q6_api_df\\\n",
    "                .filter(q6_api_df.team_type == 'home')\\\n",
    "                .select('team_goals')\\\n",
    "                .distinct()\\\n",
    "                .collect()[0]['team_goals']\n",
    "\n",
    "away_goals = q6_api_df\\\n",
    "                .filter(q6_api_df.team_type == 'away')\\\n",
    "                .select('team_goals')\\\n",
    "                .distinct()\\\n",
    "                .collect()[0]['team_goals']\n",
    "#Appending the above dataframe with the result who is winning and who is losing\n",
    "q6_api_df = q6_api_df.withColumn(\n",
    "    \"team_result\",\n",
    "    F.when((F.col(\"team_type\") == \"home\") & (F.col(\"team_goals\") > away_goals), \"Winning\")\n",
    "    .when((F.col(\"team_type\") == \"home\") & (F.col(\"team_goals\") <= away_goals), \"Losing\")\n",
    "    .when((F.col(\"team_type\") == \"away\") & (F.col(\"team_goals\") > home_goals), \"Winning\")\n",
    "    .when((F.col(\"team_type\") == \"away\") & (F.col(\"team_goals\") <= home_goals), \"Losing\")\n",
    "    .otherwise(\"Tie\")\n",
    ")\n",
    "\n",
    "q6_api_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c8fa6c-07c7-4b52-8b44-fe99a1fe53b3",
   "metadata": {},
   "source": [
    "### Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "896299ce-8643-44ac-b6c3-152483b2e4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-----------+------------------+------------------+-------------------------+\n",
      "|teamid|player_jersey_number|player_name|current_game_shots|current_game_goals|current_game_goal_percent|\n",
      "+------+--------------------+-----------+------------------+------------------+-------------------------+\n",
      "|   101|                   1|      sarah|                 8|                 6|                     75.0|\n",
      "|   101|                   2|      steve|                 7|                 2|                    28.57|\n",
      "|   101|                   4|      shree|                 5|                 1|                     20.0|\n",
      "|   101|                   6|        sam|                 4|                 2|                     50.0|\n",
      "|   101|                   8|        sly|                 4|                 0|                      0.0|\n",
      "|   101|                   9|        sol|                 5|                 0|                      0.0|\n",
      "|   101|                  10|      swede|                 3|                 1|                    33.33|\n",
      "|   101|                  13|      stone|                 7|                 1|                    14.29|\n",
      "|   101|                  15|     shelly|                 3|                 1|                    33.33|\n",
      "|   101|                  17|       sean|                 2|                 0|                      0.0|\n",
      "+------+--------------------+-----------+------------------+------------------+-------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-----------+------------------+------------------+-------------------------+\n",
      "|teamid|player_jersey_number|player_name|current_game_shots|current_game_goals|current_game_goal_percent|\n",
      "+------+--------------------+-----------+------------------+------------------+-------------------------+\n",
      "|   205|                   1|      jimmy|                 3|                 3|                    100.0|\n",
      "|   205|                   2|      james|                 3|                 1|                    33.33|\n",
      "|   205|                   3|       jane|                 1|                 0|                      0.0|\n",
      "|   205|                   5|      jimmy|                 2|                 1|                     50.0|\n",
      "|   205|                   8|      julie|                 2|                 1|                     50.0|\n",
      "|   205|                   9|      julie|                 4|                 0|                      0.0|\n",
      "|   205|                  15|       jane|                 2|                 2|                    100.0|\n",
      "|   205|                  16|      jimmy|                 1|                 0|                      0.0|\n",
      "|   205|                  17|      james|                 3|                 1|                    33.33|\n",
      "|   205|                  22|      julie|                 1|                 0|                      0.0|\n",
      "+------+--------------------+-----------+------------------+------------------+-------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---------+----------+-----------------+-------------------+----------+-----------+\n",
      "|event_id|teamid|team_name|conference|team_overall_wins|team_overall_losses|team_goals|team_result|\n",
      "+--------+------+---------+----------+-----------------+-------------------+----------+-----------+\n",
      "|      70|   101| syracuse|       acc|               11|                  2|        14|    Winning|\n",
      "+--------+------+---------+----------+-----------------+-------------------+----------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-------------+----------+-----------------+-------------------+----------+-----------+\n",
      "|event_id|teamid|    team_name|conference|team_overall_wins|team_overall_losses|team_goals|team_result|\n",
      "+--------+------+-------------+----------+-----------------+-------------------+----------+-----------+\n",
      "|      70|   205|johns hopkins|     big10|                9|                  4|         9|     Losing|\n",
      "+--------+------+-------------+----------+-----------------+-------------------+----------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|event_id|timestamp|\n",
      "+--------+---------+\n",
      "|      70|    00:00|\n",
      "+--------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---------+----------+-----------------+-------------------+----------+-----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|event_id|teamid|team_name|conference|team_overall_wins|team_overall_losses|team_goals|team_result|players                                                                                                                                                                                                                                        |\n",
      "+--------+------+---------+----------+-----------------+-------------------+----------+-----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|70      |101   |syracuse |acc       |11               |2                  |14        |Winning    |[{1, sarah, 8, 6, 75.0}, {2, steve, 7, 2, 28.57}, {4, shree, 5, 1, 20.0}, {6, sam, 4, 2, 50.0}, {8, sly, 4, 0, 0.0}, {9, sol, 5, 0, 0.0}, {10, swede, 3, 1, 33.33}, {13, stone, 7, 1, 14.29}, {15, shelly, 3, 1, 33.33}, {17, sean, 2, 0, 0.0}]|\n",
      "+--------+------+---------+----------+-----------------+-------------------+----------+-----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-------------+----------+-----------------+-------------------+----------+-----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|event_id|teamid|team_name    |conference|team_overall_wins|team_overall_losses|team_goals|team_result|players                                                                                                                                                                                                                                           |\n",
      "+--------+------+-------------+----------+-----------------+-------------------+----------+-----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|70      |205   |johns hopkins|big10     |9                |4                  |9         |Losing     |[{1, jimmy, 3, 3, 100.0}, {2, james, 3, 1, 33.33}, {3, jane, 1, 0, 0.0}, {5, jimmy, 2, 1, 50.0}, {8, julie, 2, 1, 50.0}, {9, julie, 4, 0, 0.0}, {15, jane, 2, 2, 100.0}, {16, jimmy, 1, 0, 0.0}, {17, james, 3, 1, 33.33}, {22, julie, 1, 0, 0.0}]|\n",
      "+--------+------+-------------+----------+-----------------+-------------------+----------+-----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------------------+--------------------+\n",
      "|_id|timestamp|                home|                away|\n",
      "+---+---------+--------------------+--------------------+\n",
      "| 70|    00:00|{101, syracuse, a...|{205, johns hopki...|\n",
      "+---+---------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: integer (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- home: struct (nullable = false)\n",
      " |    |-- teamid: integer (nullable = true)\n",
      " |    |-- teamname: string (nullable = true)\n",
      " |    |-- conference: string (nullable = true)\n",
      " |    |-- wins: integer (nullable = true)\n",
      " |    |-- losses: integer (nullable = true)\n",
      " |    |-- score: long (nullable = true)\n",
      " |    |-- status: string (nullable = true)\n",
      " |    |-- players: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = false)\n",
      " |    |    |    |-- player_jersey_number: integer (nullable = true)\n",
      " |    |    |    |-- player_name: string (nullable = true)\n",
      " |    |    |    |-- current_game_shots: long (nullable = false)\n",
      " |    |    |    |-- current_game_goals: long (nullable = true)\n",
      " |    |    |    |-- current_game_goal_percent: double (nullable = false)\n",
      " |-- away: struct (nullable = false)\n",
      " |    |-- teamid: integer (nullable = true)\n",
      " |    |-- teamname: string (nullable = true)\n",
      " |    |-- conference: string (nullable = true)\n",
      " |    |-- wins: integer (nullable = true)\n",
      " |    |-- losses: integer (nullable = true)\n",
      " |    |-- score: long (nullable = true)\n",
      " |    |-- status: string (nullable = true)\n",
      " |    |-- players: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = false)\n",
      " |    |    |    |-- player_jersey_number: integer (nullable = true)\n",
      " |    |    |    |-- player_name: string (nullable = true)\n",
      " |    |    |    |-- current_game_shots: long (nullable = false)\n",
      " |    |    |    |-- current_game_goals: long (nullable = true)\n",
      " |    |    |    |-- current_game_goal_percent: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Player Level Data\n",
    "q7_api_home_players_data = q6_api_df\\\n",
    "                                .filter(q6_api_df.team_type == 'home')\\\n",
    "                                .select('teamid','player_jersey_number','player_name','current_game_shots','current_game_goals','current_game_goal_percent')\\\n",
    "                                .sort(q6_api_df.player_jersey_number)\n",
    "\n",
    "q7_api_away_players_data = q6_api_df\\\n",
    "                                .filter(q6_api_df.team_type == 'away')\\\n",
    "                                .select('teamid','player_jersey_number','player_name','current_game_shots','current_game_goals','current_game_goal_percent')\\\n",
    "                                .sort(q6_api_df.player_jersey_number)\n",
    "\n",
    "q7_api_home_players_data.show()\n",
    "q7_api_away_players_data.show()\n",
    "\n",
    "#Team Level Data:\n",
    "q7_api_home_team_data = q6_api_df\\\n",
    "                            .filter(q6_api_df.team_type == 'home')\\\n",
    "                            .select('event_id','teamid','team_name','conference','team_overall_wins','team_overall_losses','team_goals','team_result')\\\n",
    "                            .distinct()\n",
    "\n",
    "q7_api_away_team_data = q6_api_df\\\n",
    "                            .filter(q6_api_df.team_type == 'away')\\\n",
    "                            .select('event_id','teamid','team_name','conference','team_overall_wins','team_overall_losses','team_goals','team_result')\\\n",
    "                            .distinct()\n",
    "\n",
    "q7_api_home_team_data.show()\n",
    "q7_api_away_team_data.show()\n",
    "\n",
    "#Event Level Data\n",
    "q7_api_event_data = q6_api_df\\\n",
    "                            .select('event_id','timestamp')\\\n",
    "                            .distinct()\n",
    "\n",
    "q7_api_event_data.show()\n",
    "\n",
    "# struct for player details\n",
    "player_struct = F.struct(\n",
    "    F.col(\"player_jersey_number\").alias(\"player_jersey_number\"),\n",
    "    F.col(\"player_name\").alias(\"player_name\"),\n",
    "    F.col(\"current_game_shots\").alias(\"current_game_shots\"),\n",
    "    F.col(\"current_game_goals\").alias(\"current_game_goals\"),\n",
    "    F.col(\"current_game_goal_percent\").alias(\"current_game_goal_percent\")\n",
    ")\n",
    "\n",
    "# array of player details\n",
    "players_array = F.sort_array(F.collect_list(player_struct), asc=True).alias(\"players\")\n",
    "\n",
    "# Join the team data with players and group by teamid\n",
    "home_team_with_players_df = q7_api_home_team_data.alias(\"t\")\\\n",
    "    .join(q7_api_home_players_data.alias(\"p\"), \"teamid\")\\\n",
    "    .groupBy(\"t.event_id\",\"t.teamid\", \"t.team_name\", \"t.conference\", \"t.team_overall_wins\", \"t.team_overall_losses\", \"t.team_goals\",\"t.team_result\")\\\n",
    "    .agg(\n",
    "        players_array\n",
    "    )\\\n",
    "    .select(\n",
    "        F.col(\"event_id\"),\n",
    "        F.col(\"teamid\"),\n",
    "        F.col(\"team_name\"),\n",
    "        F.col(\"conference\"),\n",
    "        F.col(\"team_overall_wins\"),\n",
    "        F.col(\"team_overall_losses\"),\n",
    "        F.col(\"team_goals\"),\n",
    "        F.col(\"team_result\"),\n",
    "        F.col(\"players\")\n",
    "    )\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "home_team_with_players_df.show(truncate=False)\n",
    "home_team_with_players_df.write.json(\"home_team_with_players.json\", mode=\"overwrite\")\n",
    "\n",
    "# Create a struct for player details\n",
    "player_struct = F.struct(\n",
    "    F.col(\"player_jersey_number\").alias(\"player_jersey_number\"),\n",
    "    F.col(\"player_name\").alias(\"player_name\"),\n",
    "    F.col(\"current_game_shots\").alias(\"current_game_shots\"),\n",
    "    F.col(\"current_game_goals\").alias(\"current_game_goals\"),\n",
    "    F.col(\"current_game_goal_percent\").alias(\"current_game_goal_percent\")\n",
    ")\n",
    "\n",
    "# array of player details\n",
    "players_array = F.sort_array(F.collect_list(player_struct), asc=True).alias(\"players\")\n",
    "\n",
    "# Join the team data with players and group by teamid\n",
    "away_team_with_players_df = q7_api_away_team_data.alias(\"t\")\\\n",
    "    .join(q7_api_away_players_data.alias(\"p\"), \"teamid\")\\\n",
    "    .groupBy(\"t.event_id\",\"t.teamid\", \"t.team_name\", \"t.conference\", \"t.team_overall_wins\", \"t.team_overall_losses\", \"t.team_goals\",\"t.team_result\")\\\n",
    "    .agg(\n",
    "        players_array\n",
    "    )\\\n",
    "    .select(\n",
    "        F.col(\"event_id\"),\n",
    "        F.col(\"teamid\"),\n",
    "        F.col(\"team_name\"),\n",
    "        F.col(\"conference\"),\n",
    "        F.col(\"team_overall_wins\"),\n",
    "        F.col(\"team_overall_losses\"),\n",
    "        F.col(\"team_goals\"),\n",
    "        F.col(\"team_result\"),\n",
    "        F.col(\"players\")\n",
    "    )\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "away_team_with_players_df.show(truncate=False)\n",
    "away_team_with_players_df.write.json(\"away_team_with_players.json\", mode=\"overwrite\")\n",
    "\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "# Select the desired columns for home team\n",
    "home_team_final_df = home_team_with_players_df.select(\n",
    "    F.col(\"event_id\").alias(\"home_event_id\"),\n",
    "    F.col(\"teamid\").alias(\"home_teamid\"),\n",
    "    F.col(\"team_name\").alias(\"home_teamname\"),\n",
    "    F.col(\"conference\").alias(\"home_conference\"),\n",
    "    F.col(\"team_overall_wins\").alias(\"home_wins\"),\n",
    "    F.col(\"team_overall_losses\").alias(\"home_losses\"),\n",
    "    F.col(\"team_goals\").alias(\"home_score\"),\n",
    "    F.col(\"team_result\").alias(\"home_status\"),\n",
    "    F.col(\"players\").alias(\"home_players\")\n",
    ")\n",
    "\n",
    "# Select the desired columns for away team\n",
    "away_team_final_df = away_team_with_players_df.select(\n",
    "    F.col(\"event_id\").alias(\"away_event_id\"),\n",
    "    F.col(\"teamid\").alias(\"away_teamid\"),\n",
    "    F.col(\"team_name\").alias(\"away_teamname\"),\n",
    "    F.col(\"conference\").alias(\"away_conference\"),\n",
    "    F.col(\"team_overall_wins\").alias(\"away_wins\"),\n",
    "    F.col(\"team_overall_losses\").alias(\"away_losses\"),\n",
    "    F.col(\"team_goals\").alias(\"away_score\"),\n",
    "    F.col(\"team_result\").alias(\"away_status\"),\n",
    "    F.col(\"players\").alias(\"away_players\")\n",
    ")\n",
    "\n",
    "# distinct event details\n",
    "event_details_df = q7_api_event_data.select(\"event_id\", \"timestamp\")\n",
    "\n",
    "# Join home team data with event details\n",
    "home_team_event_df = event_details_df.join(home_team_final_df, F.col(\"event_id\") == F.col(\"home_event_id\"), \"left\")\n",
    "\n",
    "# Join away team data with event details\n",
    "final_team_player_event_data = home_team_event_df.join(away_team_final_df, F.col(\"event_id\") == F.col(\"away_event_id\"), \"left\")\n",
    "\n",
    "# Select columns for the final DataFrame\n",
    "final_team_player_event_data = final_team_player_event_data.select(\n",
    "    F.col(\"event_id\").alias(\"_id\"),\n",
    "    F.col(\"timestamp\"),\n",
    "    F.struct(\n",
    "        F.col(\"home_teamid\").alias(\"teamid\"),\n",
    "        F.col(\"home_teamname\").alias(\"teamname\"),\n",
    "        F.col(\"home_conference\").alias(\"conference\"),\n",
    "        F.col(\"home_wins\").alias(\"wins\"),\n",
    "        F.col(\"home_losses\").alias(\"losses\"),\n",
    "        F.col(\"home_score\").alias(\"score\"),\n",
    "        F.col(\"home_status\").alias(\"status\"),\n",
    "        F.col(\"home_players\").alias(\"players\")\n",
    "    ).alias(\"home\"),\n",
    "    F.struct(\n",
    "        F.col(\"away_teamid\").alias(\"teamid\"),\n",
    "        F.col(\"away_teamname\").alias(\"teamname\"),\n",
    "        F.col(\"away_conference\").alias(\"conference\"),\n",
    "        F.col(\"away_wins\").alias(\"wins\"),\n",
    "        F.col(\"away_losses\").alias(\"losses\"),\n",
    "        F.col(\"away_score\").alias(\"score\"),\n",
    "        F.col(\"away_status\").alias(\"status\"),\n",
    "        F.col(\"away_players\").alias(\"players\")\n",
    "    ).alias(\"away\")\n",
    ")\n",
    "\n",
    "#Final Dataframe\n",
    "final_team_player_event_data.show()\n",
    "final_team_player_event_data.write.json(\"final_team_player_event_data.json\", mode=\"overwrite\")\n",
    "final_team_player_event_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9615acf1-816c-4df6-8f75-029ab1c70b74",
   "metadata": {},
   "source": [
    "### Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "545d70e0-b091-41a7-8800-7c20063aee84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Writing output from Q7 to mongo db \n",
    "final_team_player_event_data.write.format(\"mongo\").mode(\"overwrite\")\\\n",
    "      .option(\"database\",\"sidearm\").option(\"collection\",\"boxscores\")\\\n",
    "      .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f548af-ba96-41bc-869b-c3b013f779b7",
   "metadata": {},
   "source": [
    "### Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcbdaaf-680f-4263-b4a0-2c7a7b6a17fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------------------+--------------------+\n",
      "|_id|timestamp|                home|                away|\n",
      "+---+---------+--------------------+--------------------+\n",
      "| 70|    00:00|{101, syracuse, a...|{205, johns hopki...|\n",
      "+---+---------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1026:(112 + 1) / 200][Stage 1028:> (0 + 0) / 1][Stage 1029:(0 + 0) / 200]\r"
     ]
    }
   ],
   "source": [
    "#Q3\n",
    "# TODO: Read the gamestream.txt from minio\n",
    "#With the help of StructType we are creating a schema for the data to be read from Minio (Object Storage).\n",
    "myschema = StructType([StructField('event_id',IntegerType()),\n",
    "                       StructField('timestamp',StringType()),\n",
    "                       StructField('team_id',IntegerType()),\n",
    "                       StructField('player_jersey_number',IntegerType()),\n",
    "                       StructField('hit_or_miss',IntegerType())\n",
    "                    ])\n",
    "\n",
    "gamestream_df = spark.read\\\n",
    "      .csv(f\"s3a://{s3_bucket}/gamestream.txt\", schema = myschema, sep = ' ')\n",
    "\n",
    "#Read data using csv function so we could apply the schema.\n",
    "\n",
    "# Q4 - PySpark API\n",
    "\n",
    "#Calculating Player Stats\n",
    "#To calculate player stats we are left joining players data with gamestream data so we get all players even the players that are missing in gamestream data and then counting their stats like shots and goals. We are also filling NULL values with 0. \n",
    "temp_df = players_df\\\n",
    "            .join(gamestream_df, (players_df.teamid == gamestream_df.team_id) & (players_df.number == gamestream_df.player_jersey_number), \"left\")\\\n",
    "            .select(players_df.teamid,players_df.number,gamestream_df.hit_or_miss)\\\n",
    "            .groupby('teamid','number')\\\n",
    "            .agg(count(\"hit_or_miss\").alias(\"shots\")\\\n",
    "                 ,sum(\"hit_or_miss\").alias(\"goals\"))\\\n",
    "            .na.fill(0)\n",
    "\n",
    "#Calculating team Stats\n",
    "#Here are are aggregating goals and grouping by team.\n",
    "temp_df1 = gamestream_df\\\n",
    "            .select('team_id','hit_or_miss')\\\n",
    "            .groupby('team_id')\\\n",
    "            .agg(sum('hit_or_miss').alias('team_goals'))\n",
    "\n",
    "\n",
    "#Merging both dataframes created above to create expected result.\n",
    "\n",
    "q4_api_df = temp_df\\\n",
    "        .join(temp_df1, temp_df1.team_id == temp_df.teamid, \"inner\")\\\n",
    "        .select(\"teamid\",\"number\",\"shots\",\"goals\",\"team_goals\")\\\n",
    "        .sort('teamid','number')\n",
    "\n",
    "#Q5 PySpark API\n",
    "\n",
    "#Getting the maximum event id and storing it in a variable.\n",
    "max_event_id = gamestream_df\\\n",
    "                .agg(max('event_id').alias('max_event_id'))\\\n",
    "                .collect()[0]['max_event_id']\n",
    "#Getting eventid, timestamp from gamestream and joining it with dataframe from the Q4\n",
    "q5_api_df = gamestream_df \\\n",
    "               .select('event_id','timestamp') \\\n",
    "               .filter(F.col('event_id') == F.lit(max_event_id)) \\\n",
    "               .join(q4_api_df)\\\n",
    "               .sort('teamid','number')\n",
    "\n",
    "\n",
    "#Q6 \n",
    "\n",
    "#Getting data from the table created in Q5 and joining it with players and teams data to get relevent data.\n",
    "q6_api_df = q5_api_df\\\n",
    "        .join(players_df, (q5_api_df.teamid == players_df.teamid) & (q5_api_df.number == players_df.number))\\\n",
    "        .join(teams_df, q5_api_df.teamid == teams_df.id)\\\n",
    "        .select(q5_api_df.event_id\n",
    "               ,q5_api_df.timestamp\n",
    "               ,q5_api_df.teamid\n",
    "               ,teams_df.name.alias('team_name')\n",
    "               ,teams_df.conference\n",
    "               ,teams_df.wins.alias('team_overall_wins')\n",
    "               ,teams_df.losses.alias('team_overall_losses')\n",
    "               ,q5_api_df.number.alias('player_jersey_number')\n",
    "               ,players_df.name.alias('player_name')\n",
    "               ,q5_api_df.shots.alias('current_game_shots')\n",
    "               ,q5_api_df.goals.alias('current_game_goals')\n",
    "               ,round((q5_api_df.goals / q5_api_df.shots) * 100,2).alias('current_game_goal_percent')\n",
    "               ,q5_api_df.team_goals)\\\n",
    "        .withColumn(\"team_type\", when(q5_api_df.teamid == 101, 'home').otherwise('away'))\\\n",
    "        .na.fill(0)\\\n",
    "        .sort(q5_api_df.teamid,q5_api_df.number)\\\n",
    "#Calculating goals scored by home and away team.\n",
    "home_goals = q6_api_df\\\n",
    "                .filter(q6_api_df.team_type == 'home')\\\n",
    "                .select('team_goals')\\\n",
    "                .distinct()\\\n",
    "                .collect()[0]['team_goals']\n",
    "\n",
    "away_goals = q6_api_df\\\n",
    "                .filter(q6_api_df.team_type == 'away')\\\n",
    "                .select('team_goals')\\\n",
    "                .distinct()\\\n",
    "                .collect()[0]['team_goals']\n",
    "#Appending the above dataframe with the result who is winning and who is losing\n",
    "q6_api_df = q6_api_df.withColumn(\n",
    "    \"team_result\",\n",
    "    F.when((F.col(\"team_type\") == \"home\") & (F.col(\"team_goals\") > away_goals), \"Winning\")\n",
    "    .when((F.col(\"team_type\") == \"home\") & (F.col(\"team_goals\") <= away_goals), \"Losing\")\n",
    "    .when((F.col(\"team_type\") == \"away\") & (F.col(\"team_goals\") > home_goals), \"Winning\")\n",
    "    .when((F.col(\"team_type\") == \"away\") & (F.col(\"team_goals\") <= home_goals), \"Losing\")\n",
    "    .otherwise(\"Tie\")\n",
    ")\n",
    "\n",
    "#Q7\n",
    "\n",
    "#Player Level Data\n",
    "q7_api_home_players_data = q6_api_df\\\n",
    "                                .filter(q6_api_df.team_type == 'home')\\\n",
    "                                .select('teamid','player_jersey_number','player_name','current_game_shots','current_game_goals','current_game_goal_percent')\\\n",
    "                                .sort(q6_api_df.player_jersey_number)\n",
    "\n",
    "q7_api_away_players_data = q6_api_df\\\n",
    "                                .filter(q6_api_df.team_type == 'away')\\\n",
    "                                .select('teamid','player_jersey_number','player_name','current_game_shots','current_game_goals','current_game_goal_percent')\\\n",
    "                                .sort(q6_api_df.player_jersey_number)\n",
    "#Team Level Data:\n",
    "q7_api_home_team_data = q6_api_df\\\n",
    "                            .filter(q6_api_df.team_type == 'home')\\\n",
    "                            .select('event_id','teamid','team_name','conference','team_overall_wins','team_overall_losses','team_goals','team_result')\\\n",
    "                            .distinct()\n",
    "\n",
    "q7_api_away_team_data = q6_api_df\\\n",
    "                            .filter(q6_api_df.team_type == 'away')\\\n",
    "                            .select('event_id','teamid','team_name','conference','team_overall_wins','team_overall_losses','team_goals','team_result')\\\n",
    "                            .distinct()\n",
    "\n",
    "#Event Level Data\n",
    "q7_api_event_data = q6_api_df\\\n",
    "                            .select('event_id','timestamp')\\\n",
    "                            .distinct()\n",
    "\n",
    "# struct for player details\n",
    "player_struct = F.struct(\n",
    "    F.col(\"player_jersey_number\").alias(\"player_jersey_number\"),\n",
    "    F.col(\"player_name\").alias(\"player_name\"),\n",
    "    F.col(\"current_game_shots\").alias(\"current_game_shots\"),\n",
    "    F.col(\"current_game_goals\").alias(\"current_game_goals\"),\n",
    "    F.col(\"current_game_goal_percent\").alias(\"current_game_goal_percent\")\n",
    ")\n",
    "\n",
    "# array of player details\n",
    "players_array = F.sort_array(F.collect_list(player_struct), asc=True).alias(\"players\")\n",
    "\n",
    "# Join the team data with players and group by teamid\n",
    "home_team_with_players_df = q7_api_home_team_data.alias(\"t\")\\\n",
    "    .join(q7_api_home_players_data.alias(\"p\"), \"teamid\")\\\n",
    "    .groupBy(\"t.event_id\",\"t.teamid\", \"t.team_name\", \"t.conference\", \"t.team_overall_wins\", \"t.team_overall_losses\", \"t.team_goals\",\"t.team_result\")\\\n",
    "    .agg(\n",
    "        players_array\n",
    "    )\\\n",
    "    .select(\n",
    "        F.col(\"event_id\"),\n",
    "        F.col(\"teamid\"),\n",
    "        F.col(\"team_name\"),\n",
    "        F.col(\"conference\"),\n",
    "        F.col(\"team_overall_wins\"),\n",
    "        F.col(\"team_overall_losses\"),\n",
    "        F.col(\"team_goals\"),\n",
    "        F.col(\"team_result\"),\n",
    "        F.col(\"players\")\n",
    "    )\n",
    "\n",
    "\n",
    "# Create a struct for player details\n",
    "player_struct = F.struct(\n",
    "    F.col(\"player_jersey_number\").alias(\"player_jersey_number\"),\n",
    "    F.col(\"player_name\").alias(\"player_name\"),\n",
    "    F.col(\"current_game_shots\").alias(\"current_game_shots\"),\n",
    "    F.col(\"current_game_goals\").alias(\"current_game_goals\"),\n",
    "    F.col(\"current_game_goal_percent\").alias(\"current_game_goal_percent\")\n",
    ")\n",
    "\n",
    "# array of player details\n",
    "players_array = F.sort_array(F.collect_list(player_struct), asc=True).alias(\"players\")\n",
    "\n",
    "# Join the team data with players and group by teamid\n",
    "away_team_with_players_df = q7_api_away_team_data.alias(\"t\")\\\n",
    "    .join(q7_api_away_players_data.alias(\"p\"), \"teamid\")\\\n",
    "    .groupBy(\"t.event_id\",\"t.teamid\", \"t.team_name\", \"t.conference\", \"t.team_overall_wins\", \"t.team_overall_losses\", \"t.team_goals\",\"t.team_result\")\\\n",
    "    .agg(\n",
    "        players_array\n",
    "    )\\\n",
    "    .select(\n",
    "        F.col(\"event_id\"),\n",
    "        F.col(\"teamid\"),\n",
    "        F.col(\"team_name\"),\n",
    "        F.col(\"conference\"),\n",
    "        F.col(\"team_overall_wins\"),\n",
    "        F.col(\"team_overall_losses\"),\n",
    "        F.col(\"team_goals\"),\n",
    "        F.col(\"team_result\"),\n",
    "        F.col(\"players\")\n",
    "    )\n",
    "\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "# Select the desired columns for home team\n",
    "home_team_final_df = home_team_with_players_df.select(\n",
    "    F.col(\"event_id\").alias(\"home_event_id\"),\n",
    "    F.col(\"teamid\").alias(\"home_teamid\"),\n",
    "    F.col(\"team_name\").alias(\"home_teamname\"),\n",
    "    F.col(\"conference\").alias(\"home_conference\"),\n",
    "    F.col(\"team_overall_wins\").alias(\"home_wins\"),\n",
    "    F.col(\"team_overall_losses\").alias(\"home_losses\"),\n",
    "    F.col(\"team_goals\").alias(\"home_score\"),\n",
    "    F.col(\"team_result\").alias(\"home_status\"),\n",
    "    F.col(\"players\").alias(\"home_players\")\n",
    ")\n",
    "\n",
    "# Select the desired columns for away team\n",
    "away_team_final_df = away_team_with_players_df.select(\n",
    "    F.col(\"event_id\").alias(\"away_event_id\"),\n",
    "    F.col(\"teamid\").alias(\"away_teamid\"),\n",
    "    F.col(\"team_name\").alias(\"away_teamname\"),\n",
    "    F.col(\"conference\").alias(\"away_conference\"),\n",
    "    F.col(\"team_overall_wins\").alias(\"away_wins\"),\n",
    "    F.col(\"team_overall_losses\").alias(\"away_losses\"),\n",
    "    F.col(\"team_goals\").alias(\"away_score\"),\n",
    "    F.col(\"team_result\").alias(\"away_status\"),\n",
    "    F.col(\"players\").alias(\"away_players\")\n",
    ")\n",
    "\n",
    "# distinct event details\n",
    "event_details_df = q7_api_event_data.select(\"event_id\", \"timestamp\")\n",
    "\n",
    "# Join home team data with event details\n",
    "home_team_event_df = event_details_df.join(home_team_final_df, F.col(\"event_id\") == F.col(\"home_event_id\"), \"left\")\n",
    "\n",
    "# Join away team data with event details\n",
    "final_team_player_event_data = home_team_event_df.join(away_team_final_df, F.col(\"event_id\") == F.col(\"away_event_id\"), \"left\")\n",
    "\n",
    "# Select columns for the final DataFrame\n",
    "final_team_player_event_data = final_team_player_event_data.select(\n",
    "    F.col(\"event_id\").alias(\"_id\"),\n",
    "    F.col(\"timestamp\"),\n",
    "    F.struct(\n",
    "        F.col(\"home_teamid\").alias(\"teamid\"),\n",
    "        F.col(\"home_teamname\").alias(\"teamname\"),\n",
    "        F.col(\"home_conference\").alias(\"conference\"),\n",
    "        F.col(\"home_wins\").alias(\"wins\"),\n",
    "        F.col(\"home_losses\").alias(\"losses\"),\n",
    "        F.col(\"home_score\").alias(\"score\"),\n",
    "        F.col(\"home_status\").alias(\"status\"),\n",
    "        F.col(\"home_players\").alias(\"players\")\n",
    "    ).alias(\"home\"),\n",
    "    F.struct(\n",
    "        F.col(\"away_teamid\").alias(\"teamid\"),\n",
    "        F.col(\"away_teamname\").alias(\"teamname\"),\n",
    "        F.col(\"away_conference\").alias(\"conference\"),\n",
    "        F.col(\"away_wins\").alias(\"wins\"),\n",
    "        F.col(\"away_losses\").alias(\"losses\"),\n",
    "        F.col(\"away_score\").alias(\"score\"),\n",
    "        F.col(\"away_status\").alias(\"status\"),\n",
    "        F.col(\"away_players\").alias(\"players\")\n",
    "    ).alias(\"away\")\n",
    ")\n",
    "\n",
    "#Final Dataframe\n",
    "final_team_player_event_data.show()\n",
    "final_team_player_event_data.write.json(\"final_team_player_event_data.json\", mode=\"overwrite\")\n",
    "\n",
    "\n",
    "#Q8\n",
    "#Writing output from Q7 to mongo db \n",
    "final_team_player_event_data.write.format(\"mongo\").mode(\"overwrite\")\\\n",
    "      .option(\"database\",\"sidearm\").option(\"collection\",\"boxscores\")\\\n",
    "      .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a381aca4-dce1-40af-ab87-9f35019f1713",
   "metadata": {},
   "source": [
    "### Q11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd634a64-1137-4e2c-a37a-0d6053e153b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the updated wins and losses after the game is over i.e timestamp = 00:00\n",
    "q6_api_df.createOrReplaceTempView('q6_api_df')\n",
    "sql = \"\"\"\n",
    "   WITH team_wins(team_id,updated_wins)\n",
    "   AS (SELECT DISTINCT t.id,CASE WHEN q6api.team_result = 'Winning' THEN t.wins + 1 ELSE t.wins END AS updated_wins\n",
    "        FROM teams t\n",
    "        JOIN q6_api_df q6api ON t.id = q6api.teamid\n",
    "        WHERE q6api.timestamp = '00:00'),\n",
    "    team_losses(team_id,updated_losses)\n",
    "       AS (SELECT DISTINCT t.id,CASE WHEN q6api.team_result = 'Losing' THEN t.losses + 1 ELSE t.losses END AS updated_losses\n",
    "        FROM teams t\n",
    "        JOIN q6_api_df q6api ON t.id = q6api.teamid\n",
    "        WHERE q6api.timestamp = '00:00'),\n",
    "    teams_cte(id,name,conference) AS (\n",
    "    SELECT id,name,conference FROM teams)\n",
    "    \n",
    "    SELECT t.*,tw.updated_wins,tl.updated_losses\n",
    "    FROM teams_cte t\n",
    "    JOIN team_wins tw ON t.id = tw.team_id\n",
    "    JOIN team_losses tl ON t.id = tl.team_id\n",
    "\"\"\"\n",
    "\n",
    "q11_api_df = spark.sql(sql)\n",
    "q11_api_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6413d90-9ea3-475f-80db-28e23bc0197d",
   "metadata": {},
   "source": [
    "### Q12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2934b4-2c7f-4269-9d04-94cd9e8538ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOW TO WRITE TO MSSQL\n",
    "q11_api_df.write.format(\"com.microsoft.sqlserver.jdbc.spark\") \\\n",
    "            .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .option(\"url\", mssql_url) \\\n",
    "            .option(\"dbtable\", \"teams2\") \\\n",
    "            .option(\"user\", mssql_user) \\\n",
    "            .option(\"password\", mssql_pw) \\\n",
    "            .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdd5087-84e2-4bf9-b4eb-22648bab9dcd",
   "metadata": {},
   "source": [
    "### Q13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d804d8be-14c4-44a8-afa6-27633bd6f661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting players data and latest scores from gamestream and then calculating the updated shots and goals.\n",
    "sql = \"\"\"\n",
    "WITH players_temp(id,name,number,teamid,shots,goals) AS (\n",
    "        SELECT id,\n",
    "                name,\n",
    "                number,\n",
    "                teamid,\n",
    "                shots,\n",
    "                goals \n",
    "        FROM players\n",
    "),\n",
    "q6api(teamid,player_jersey_number,current_game_shots,current_game_goals) AS (\n",
    "        SELECT teamid,\n",
    "                player_jersey_number,\n",
    "                current_game_shots,\n",
    "                current_game_goals \n",
    "        FROM q6_api_df\n",
    "        WHERE timestamp = '00:00'\n",
    ")\n",
    "SELECT pt.id,pt.name,pt.number,(pt.shots + q6.current_game_shots) updated_shots,(pt.goals + q6.current_game_goals) updated_goals,pt.teamid\n",
    "FROM players_temp pt\n",
    "JOIN q6api q6 ON q6.teamid = pt.teamid AND q6.player_jersey_number = pt.number\n",
    "ORDER BY pt.id\n",
    "\"\"\"\n",
    "q13_api_df = spark.sql(sql)\n",
    "q13_api_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cfb3d3-d2a4-46c9-be33-ffc79c5c4369",
   "metadata": {},
   "source": [
    "### Q14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e816335a-b27f-4f03-ae3b-fce1051c8034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOW TO WRITE TO MSSQL\n",
    "q13_api_df.write.format(\"com.microsoft.sqlserver.jdbc.spark\") \\\n",
    "            .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .option(\"url\", mssql_url) \\\n",
    "            .option(\"dbtable\", \"players2\") \\\n",
    "            .option(\"user\", mssql_user) \\\n",
    "            .option(\"password\", mssql_pw) \\\n",
    "            .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f24ca97-0f2d-46a5-bff4-f6cc09a26e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
